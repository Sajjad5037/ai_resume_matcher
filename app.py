import os 
import streamlit as st

import io
import pandas as pd
import json 
#from openai import OpenAI
import re
import google.generativeai as genai


import mimetypes
st.write(
    "ğŸ“Œ For best accuracy, upload CVs in DOCX or text-based PDF format. "
    "Scanned PDFs may reduce matching quality."
)


def generate_full_assessment(candidate_files, job, model_name, candidate_seniority):
    """
    Single-pass advisor-style evaluation.
    CV + JD are read together.
    Explanation first, score last.
    UI-compatible output keys.
    """

    prompt = f"""
Return ONLY valid JSON.
No markdown.
No text outside JSON.

ã‚ãªãŸã¯ã€ã‚­ãƒ£ãƒªã‚¢ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼å…¼æ¡ç”¨æ‹…å½“è€…ã§ã™ã€‚
ä»¥ä¸‹ã®å±¥æ­´æ›¸ï¼ˆCVï¼‰ã‚’ä¸å¯§ã«èª­ã¿ã€
ã“ã®æ±‚äººã«å¯¾ã—ã¦ã€Œãªãœãã†è©•ä¾¡ã—ãŸã®ã‹ã€ãŒ
ç¬¬ä¸‰è€…ã«ã‚‚åˆ†ã‹ã‚‹ã‚ˆã†ã«èª¬æ˜ã—ã¦ãã ã•ã„ã€‚

ã€é‡è¦ãªå‰æã€‘
- è©•ä¾¡ã¯æ›¸é¡é¸è€ƒæ®µéšã®ã‚‚ã®ã§ã™ã€‚
- CVã«æ˜ç¤ºçš„ã«è¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹å†…å®¹ã®ã¿ã‚’æ ¹æ‹ ã«ã—ã¦ãã ã•ã„ã€‚
- æ¨æ¸¬ã‚„æ–­å®šã¯ç¦æ­¢ã§ã™ã€‚
- ENTRYæ±‚äººã§ã¯çµŒé¨“ä¸è¶³ã‚’å¦å®šçš„ã«æ‰±ã£ã¦ã¯ã„ã‘ã¾ã›ã‚“ã€‚

ã€æ±‚äººãƒ¬ãƒ™ãƒ«ã€‘
{job["seniority"]}

ã€å€™è£œè€…ãƒ¬ãƒ™ãƒ«ã€‘
{candidate_seniority}

ã€è·å‹™å†…å®¹ã€‘
{job["job_context"][:1500]}

ã€å‡ºåŠ›JSONå½¢å¼ï¼ˆå³å®ˆï¼‰ã€‘
{{
  "SUMMARY": "",
  "MUST_HAVE": "",
  "PREFERRED": "",
  "ALIGNMENT": "",
  "score": 0
}}

ã€å„é …ç›®ã®æ„å‘³ã€‘
- SUMMARYï¼šå…¨ä½“è©•ä¾¡ï¼ˆãªãœã“ã®ã‚ˆã†ãªåˆ¤æ–­ã«ãªã£ãŸã‹ï¼‰
- MUST_HAVEï¼šå±¥æ­´æ›¸ã‹ã‚‰ç¢ºèªã§ãã‚‹ä¸»ãªå¼·ã¿ãƒ»è©•ä¾¡ã§ãã‚‹ç‚¹
- PREFERREDï¼šç¾æ™‚ç‚¹ã§æ‡¸å¿µã¨ãªã‚Šå¾—ã‚‹ç‚¹ã‚„ä¸è¶³ã—ã¦ã„ã‚‹å¯èƒ½æ€§ã®ã‚ã‚‹è¦ç´ 
- ALIGNMENTï¼šæœ¬æ±‚äººã¨ã®å½¹å‰²ãƒ»æœŸå¾…å€¤ã®é©åˆæ€§

ã€ã‚¹ã‚³ã‚¢ã«ã¤ã„ã¦ã€‘
- 0ã€œ100 ã®æ•´æ•°ã§è¿”ã—ã¦ãã ã•ã„
- ä¸Šè¨˜ã®è©•ä¾¡å†…å®¹ã¨æ•´åˆã™ã‚‹æ•°å€¤ã«ã—ã¦ãã ã•ã„
"""
    
    model = genai.GenerativeModel(model_name)

    content_parts = prompt


    
    response = model.generate_content(
        content_parts,
        generation_config={
            "temperature": 0.3,
            "max_output_tokens": 900,
        }
    )


    raw = response.text
    parsed = extract_json(raw)
    return parsed

def get_display_score(score: int, seniority: str) -> int:
    """
    UI-safe score display.
    Does NOT affect AI logic.
    """
    if seniority == "ENTRY":
        return max(score, 25)
    return score


def detect_seniority(job_context: str) -> str:
    keywords_entry = ["æœªçµŒé¨“OK", "çµŒé¨“ä¸å•", "ç¬¬äºŒæ–°å’"]

    keywords_senior = ["3å¹´ä»¥ä¸Š", "5å¹´ä»¥ä¸Š", "ãƒªãƒ¼ãƒ‰", "ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼"]

    for k in keywords_entry:
        if k in job_context:
            return "ENTRY"

    for k in keywords_senior:
        if k in job_context:
            return "SENIOR"

    return "MID"

def to_gemini_part(uploaded_file):
    uploaded_file.seek(0)

    mime_type, _ = mimetypes.guess_type(uploaded_file.name)
    if uploaded_file.name.lower().endswith(".pdf"):
        mime_type = "application/pdf"

    if not mime_type:
        mime_type = uploaded_file.type or "application/octet-stream"

    return {
        "mime_type": mime_type,
        "data": uploaded_file.read(),
    }

 
genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))

api_key = os.getenv("GOOGLE_API_KEY")

if not api_key:
    st.error("GOOGLE_API_KEY is NOT loaded. Check Streamlit Secrets.")
    st.stop()



# ----------------------------
# OpenAI setup
# ----------------------------
#if not os.getenv("OPENAI_API_KEY"):
#    st.error("OPENAI_API_KEY is NOT loaded. Check Streamlit Secrets.")
#    st.stop()

#client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))


# ----------------------------
# App Config
# ----------------------------
st.set_page_config(
    page_title="AI Resume Matcher (new)",
    layout="centered"
)
if "results" not in st.session_state:
    st.session_state.results = []

if "explanations" not in st.session_state:
    st.session_state.explanations = {}
if "explain_open" not in st.session_state:
    st.session_state.explain_open = {}

if "cvs" not in st.session_state:
    st.session_state.cvs = None
if "active_candidate" not in st.session_state:
    st.session_state.active_candidate = None

    
st.success("Gemini API key loaded successfully.")


st.title("AI Resume Matcher (hello)")



# ----------------------------
# Model Selection & Diagnostics
# ----------------------------
try:
    # This fetches the actual list from Google
    available_models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
except Exception as e:
    st.error(f"Could not fetch models: {e}")
    available_models = []
st.subheader("âœ… Available Gemini models for this project")
st.code(available_models)


# ----------------------------
# Model Selection
# ----------------------------
MODEL_OPTIONS = {
    "Gemini 1.5 Pro": "models/gemini-1.5-pro"
}

selected_model_label = st.selectbox(
    "Select AI model",
    options=list(MODEL_OPTIONS.keys()),
    index=0
)

SELECTED_MODEL = MODEL_OPTIONS[selected_model_label]

st.caption(f"Using model: `{SELECTED_MODEL}`")

st.write("Upload a candidate CV to see which jobs are most likely to result in an offer.")
st.write(
    "ğŸ“Œ For best accuracy, upload CVs in DOCX or text-based PDF format. "
    "Scanned PDFs may reduce matching quality."
)




def safe_parse_json(text):
    start = text.find("{")
    end = text.rfind("}")
    if start == -1 or end == -1 or end <= start:
        raise ValueError("No valid JSON found")
    return json.loads(text[start:end + 1])




def generate_explanation(job, evaluation, candidate_seniority):

    score = evaluation["score"]

    # ğŸ”‘ Core intent flag (THIS WAS MISSING)
    is_overqualified_for_entry = (
        job["seniority"] == "ENTRY"
        and candidate_seniority in ["MID", "SENIOR"]
    )

    prompt = f"""
Return ONLY valid JSON.
Do not include markdown.
Do not include any text outside JSON.
Do not add extra keys.

ã€æ±‚äººãƒ¬ãƒ™ãƒ«ã€‘
ã“ã®æ±‚äººã¯ã€Œ{job['seniority']} ãƒ¬ãƒ™ãƒ«ã€ã®å‹Ÿé›†ã§ã™ã€‚

ã€å€™è£œè€…ãƒ¬ãƒ™ãƒ«ã€‘
ã“ã®å€™è£œè€…ã¯ã€Œ{candidate_seniority} ãƒ¬ãƒ™ãƒ«ã€ã¨æ¨å®šã•ã‚Œã¾ã™ã€‚

ã€ã‚¹ã‚³ã‚¢ã®æ„å‘³ï¼ˆå³å®ˆï¼‰ã€‘
- æƒ³å®šå†…å®šç¢ºç‡ã¯æ›¸é¡é¸è€ƒæ®µéšã§ã®å¯èƒ½æ€§ã‚’ç¤ºã—ã¾ã™ã€‚
- ENTRY æ±‚äººã«ãŠã„ã¦ã€çµŒé¨“ä¸è¶³ã‚’å‰æã¨ã—ãŸè¡¨ç¾ã¯ç¦æ­¢ã§ã™ã€‚

ã€ãƒ¬ãƒ™ãƒ«å·®ã«é–¢ã™ã‚‹è¡¨ç¾ãƒ«ãƒ¼ãƒ«ï¼ˆæœ€é‡è¦ï¼‰ã€‘
- å€™è£œè€…ãƒ¬ãƒ™ãƒ«ãŒæ±‚äººãƒ¬ãƒ™ãƒ«ã‚’ä¸Šå›ã‚‹å ´åˆï¼š
  ä»¥ä¸‹ã®è¡¨ç¾ã®ã¿ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚
  ãƒ»å½¹å‰²æœŸå¾…ã®é•ã„
  ãƒ»æ¥­å‹™ç¯„å›²ãƒ»è²¬ä»»è¨­è¨ˆã®ç›¸é•
  ãƒ»ãƒã‚¸ã‚·ãƒ§ãƒ³ç‰¹æ€§ã¨ã®ãƒŸã‚¹ãƒãƒƒãƒ

  ä»¥ä¸‹ã®è¡¨ç¾ã¯çµ¶å¯¾ã«ä½¿ç”¨ã—ã¦ã¯ã„ã‘ã¾ã›ã‚“ã€‚
  ãƒ»è‚²æˆ
  ãƒ»å­¦ç¿’
  ãƒ»æˆé•·æ¬¡ç¬¬
  ãƒ»åˆ¤æ–­ææ–™ãŒé™ã‚‰ã‚Œã¦ã„ã‚‹

ã€è©•ä¾¡ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã€‘
- å¿…é ˆè¦ä»¶ã®è©•ä¾¡ï¼š{evaluation["criteria"]["must_have_requirements"]}
- æ­“è¿è¦ä»¶ã®è©•ä¾¡ï¼š{evaluation["criteria"]["preferred_requirements"]}
- è·å‹™å†…å®¹ã¨ã®é©åˆæ€§ï¼š{evaluation["criteria"]["role_alignment"]}
- æƒ³å®šå†…å®šç¢ºç‡ï¼š{score}ï¼…

ã€å‡ºåŠ›JSONå½¢å¼ï¼ˆå³å®ˆï¼‰ã€‘
{{
  "SUMMARY": "",
  "MUST_HAVE": "",
  "PREFERRED": "",
  "ALIGNMENT": ""
}}

ã€è·å‹™å†…å®¹ã€‘
{job["job_context"][:1200]}
"""

    model = genai.GenerativeModel(SELECTED_MODEL)

    response = model.generate_content(
        prompt,
        generation_config={"temperature": 0.3, "max_output_tokens": 900}
    )

    try:
        result = safe_parse_json(response.text)
        # ğŸ” DEBUG: confirm level pairing
        
        # ğŸš¨ HARD OVERRIDE: ENTRY job + non-ENTRY candidate
        if is_overqualified_for_entry:

            result["ALIGNMENT"] = (
                "æœ¬æ±‚äººã¯ENTRYãƒ¬ãƒ™ãƒ«ã®å½¹å‰²è¨­è¨ˆã¨ãªã£ã¦ãŠã‚Šã€"
                "å€™è£œè€…ã®çµŒé¨“æ°´æº–ã‚„æœŸå¾…å½¹å‰²ã¨ã®é–“ã«å·®ç•°ãŒè¦‹ã‚‰ã‚Œã¾ã™ã€‚"
                "æ¥­å‹™ç¯„å›²ã‚„è²¬ä»»è¨­è¨ˆã®è¦³ç‚¹ã‹ã‚‰ã€å½¹å‰²æœŸå¾…ã®æ•´ç†ãŒå¿…è¦ã§ã™ã€‚"
            )
        
            # Also clean MUST_HAVE if needed
            if "è‚²æˆ" in result.get("MUST_HAVE", ""):
                result["MUST_HAVE"] = (
                    "å¿…é ˆè¦ä»¶ã«é–¢é€£ã™ã‚‹çµŒé¨“ã¯ç¢ºèªã§ãã¾ã™ãŒã€"
                    "æœ¬æ±‚äººã§æƒ³å®šã•ã‚Œã¦ã„ã‚‹å½¹å‰²æ°´æº–ã¨ã¯ä¸€éƒ¨ç•°ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚"
                )
            if (
                "è‚²æˆ" in result.get("SUMMARY", "")
                or "æˆé•·" in result.get("SUMMARY", "")
            ):
                result["SUMMARY"] = (
                    "å±¥æ­´æ›¸ã®å†…å®¹ã‹ã‚‰ã€å½“è©²è·ç¨®ã«å¯¾ã—ã¦ä¸€å®šã®å¯èƒ½æ€§ã¯è¦‹ã‚‰ã‚Œã¾ã™ãŒã€"
                    "æœ¬æ±‚äººã®å½¹å‰²è¨­è¨ˆã¨ã®é–“ã«æœŸå¾…å€¤ã®é•ã„ãŒè¦‹å—ã‘ã‚‰ã‚Œã¾ã™ã€‚"
                )
        
        return result
        

    except Exception:
        # ---------- FALLBACK (STRICT & INTENT-AWARE) ----------

        # âŒ Low score & non-entry â†’ strict allowed
        if score < 20 and job["seniority"] != "ENTRY":
            return {
                "SUMMARY": "æä¾›ã•ã‚ŒãŸå±¥æ­´æ›¸ã®å†…å®¹ã‹ã‚‰ã€å½“è©²è·ç¨®ã«ãŠã„ã¦ç¾æ™‚ç‚¹ã§ã®å†…å®šå¯èƒ½æ€§ã¯é™å®šçš„ã§ã‚ã‚‹ã¨è€ƒãˆã‚‰ã‚Œã¾ã™ã€‚",
                "MUST_HAVE": "å¿…é ˆè¦ä»¶ã«è©²å½“ã™ã‚‹è·å‹™çµŒé¨“ã‚„æˆæœãŒã€å±¥æ­´æ›¸ä¸Šã§ã¯ååˆ†ã«ç¢ºèªã§ãã¾ã›ã‚“ã§ã—ãŸã€‚",
                "PREFERRED": "æ­“è¿è¦ä»¶ã«ã¤ã„ã¦ã‚‚ã€ç›´æ¥çš„ãªé©åˆæ€§ã‚’ç¤ºã™è¨˜è¼‰ã¯é™å®šçš„ã§ã™ã€‚",
                "ALIGNMENT": "è·å‹™å†…å®¹ã¨ã®ç›´æ¥çš„ãªä¸€è‡´ã¯ç¢ºèªã§ããšã€å½¹å‰²è¦ä»¶ã¨ã®ä¹–é›¢ãŒè¦‹ã‚‰ã‚Œã¾ã™ã€‚"
            }

        # âš ï¸ Medium score
        elif score < 60:

            # âœ… ENTRY job but candidate is ABOVE entry â†’ role mismatch
            if is_overqualified_for_entry:
                return {
                    "SUMMARY": "å±¥æ­´æ›¸ã®å†…å®¹ã‹ã‚‰ã€å½“è©²è·ç¨®ã«å¯¾ã—ã¦ä¸€å®šã®å¯èƒ½æ€§ã¯è¦‹ã‚‰ã‚Œã‚‹ã‚‚ã®ã®ã€å½¹å‰²è¨­è¨ˆã¨ã®è¦³ç‚¹ã§æ…é‡ãªæ¤œè¨ãŒå¿…è¦ã¨è€ƒãˆã‚‰ã‚Œã¾ã™ã€‚",
                    "MUST_HAVE": "å¿…é ˆè¦ä»¶ã«é–¢é€£ã™ã‚‹çµŒé¨“ã‚„å®Ÿç¸¾ã¯ç¢ºèªã§ãã¾ã™ãŒã€æœ¬æ±‚äººã§æƒ³å®šã•ã‚Œã¦ã„ã‚‹å½¹å‰²æ°´æº–ã¨ã¯ä¸€éƒ¨ä¹–é›¢ãŒè¦‹ã‚‰ã‚Œã¾ã™ã€‚",
                    "PREFERRED": "æ­“è¿è¦ä»¶ã«ã¤ã„ã¦ã¯æ´»ã‹ã›ã‚‹è¦ç´ ãŒç¢ºèªã§ãã¾ã™ãŒã€æ¥­å‹™ç¯„å›²ã‚„æœŸå¾…å½¹å‰²ã¨ã®æ•´ç†ãŒå¿…è¦ã§ã™ã€‚",
                    "ALIGNMENT": "æœ¬æ±‚äººã¯ENTRYãƒ¬ãƒ™ãƒ«ã®å½¹å‰²è¨­è¨ˆã¨ãªã£ã¦ãŠã‚Šã€å€™è£œè€…ã®çµŒé¨“æ°´æº–ã¨ã¯å½¹å‰²æœŸå¾…ã®é•ã„ãŒç”Ÿã˜ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚"
                }

            # âœ… True ENTRY candidate â†’ growth framing allowed
            if candidate_seniority == "ENTRY" and job["seniority"] == "ENTRY":
                return {
                    "SUMMARY": "å±¥æ­´æ›¸ã®å†…å®¹ã‹ã‚‰ã€å½“è©²è·ç¨®ã«ãŠã„ã¦ä¸€å®šã®æ¤œè¨ä½™åœ°ãŒã‚ã‚‹ã¨è€ƒãˆã‚‰ã‚Œã¾ã™ã€‚",
                    "MUST_HAVE": "å¿…é ˆè¦ä»¶ã«ã¤ã„ã¦ã¯æ˜ç¢ºãªçµŒé¨“ã®è¨˜è¼‰ã¯é™å®šçš„ã§ã™ãŒã€è‚²æˆã‚„å­¦ç¿’ã«ã‚ˆã£ã¦è£œå®Œå¯èƒ½ãªä½™åœ°ãŒã‚ã‚Šã¾ã™ã€‚",
                    "PREFERRED": "æ­“è¿è¦ä»¶ã«ã¤ã„ã¦ã¯ä¸€éƒ¨ã«é–¢é€£æ€§ãŒè¦‹ã‚‰ã‚Œã‚‹ã‚‚ã®ã®ã€é™å®šçš„ãªå†…å®¹ã«ã¨ã©ã¾ã£ã¦ã„ã¾ã™ã€‚",
                    "ALIGNMENT": "è·å‹™å†…å®¹ã¨ã®è¦ªå’Œæ€§ã«ã¤ã„ã¦ã¯ã€ä»Šå¾Œã®è‚²æˆéç¨‹ã‚’è¸ã¾ãˆãŸè©•ä¾¡ãŒæƒ³å®šã•ã‚Œã¾ã™ã€‚"
                }

            # MID / SENIOR normal case
            return {
                "SUMMARY": "å±¥æ­´æ›¸ã®å†…å®¹ã‹ã‚‰ã€å½“è©²è·ç¨®ã«ãŠã„ã¦ä¸€å®šã®å¯èƒ½æ€§ãŒè¦‹ã‚‰ã‚Œã¾ã™ã€‚",
                "MUST_HAVE": "å¿…é ˆè¦ä»¶ã«é–¢é€£ã™ã‚‹å®Ÿå‹™çµŒé¨“ã‚„æˆæœã¯ç¢ºèªã§ãã¾ã™ãŒã€æ±‚äººã§æƒ³å®šã•ã‚Œã¦ã„ã‚‹å½¹å‰²ã‚„æœŸå¾…ã¨ã®é–“ã«ä¸€éƒ¨å·®ç•°ãŒè¦‹ã‚‰ã‚Œã¾ã™ã€‚",
                "PREFERRED": "æ­“è¿è¦ä»¶ã«ã¤ã„ã¦ã¯ã€è·å‹™ã«æ´»ã‹ã›ã‚‹è¦ç´ ãŒä¸€éƒ¨ç¢ºèªã§ãã¾ã™ã€‚",
                "ALIGNMENT": "è·å‹™å†…å®¹ã¨ã®é©åˆæ€§ã«ã¤ã„ã¦ã¯ã€å½¹å‰²æœŸå¾…ã®é•ã„ã‚’è¸ã¾ãˆãŸæ¤œè¨ãŒå¿…è¦ã§ã™ã€‚"
            }

        # âœ… High score â†’ positive framing
        else:
            return {
                "SUMMARY": "å±¥æ­´æ›¸ã®å†…å®¹ã‹ã‚‰ã€å½“è©²è·ç¨®ã¨ã®é©åˆæ€§ãŒä¸€å®šç¨‹åº¦ç¢ºèªã§ãã€å‰å‘ãã«æ¤œè¨ã§ãã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚",
                "MUST_HAVE": "å¿…é ˆè¦ä»¶ã«ã¤ã„ã¦ã¯ã€è·å‹™ã«é–¢é€£ã™ã‚‹ååˆ†ãªçµŒé¨“ã‚„æˆæœãŒç¢ºèªã§ãã¾ã™ã€‚",
                "PREFERRED": "æ­“è¿è¦ä»¶ã«ã¤ã„ã¦ã‚‚ã€è©•ä¾¡å¯èƒ½ãªè¦ç´ ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚",
                "ALIGNMENT": "è·å‹™å†…å®¹ã¨ã®è¦ªå’Œæ€§ã¯æ¯”è¼ƒçš„é«˜ãã€æ¥­å‹™ã¸ã®é©å¿œãŒæœŸå¾…ã•ã‚Œã¾ã™ã€‚"
            }

def generate_with_retry(model, prompt, candidate_files, retries=1):
    last_error = None

    for attempt in range(1, retries + 1):
        response = model.generate_content(
            prompt,  # âœ… now defined via parameter
            generation_config={
                "temperature": 0.3,
                "max_output_tokens": 900,
            }
        )

        candidate = response.candidates[0]
        raw = candidate.content.parts[0].text

        try:
            parsed = extract_json(raw)
            return parsed, raw
        except Exception as e:
            last_error = e

    raise ValueError(f"Failed after retries: {last_error}")

def extract_json(text):
    # Find the first opening brace
    start = text.find("{")
    if start == -1:
        raise ValueError("No JSON object found in model output")

    # Find the last closing brace
    end = text.rfind("}")
    if end == -1 or end <= start:
        raise ValueError("Incomplete JSON object in model output")

    json_str = text[start:end + 1]

    try:
        return json.loads(json_str)
    except json.JSONDecodeError as e:
        raise ValueError(f"Invalid JSON returned by model: {e}")
# ----------------------------
# Helpers
# ----------------------------
def detect_candidate_seniority_from_cv(candidate_files):
    # Document-based seniority inference is intentionally disabled
    # because we rely on Gemini's internal document understanding.
    return "ENTRY"


def get_title(row):
    for key in ["title", "position"]:
        if key in row.index:
            value = row[key]
            if not pd.isna(value) and str(value).strip():
                return str(value).strip()
    return "Unknown Role"


def get_available_jobs(df: pd.DataFrame):
    """
    Builds structured job contexts from uploaded Excel file
    """
    df.columns = df.columns.astype(str).str.strip()

    jobs = []

    def safe(value):
        if pd.isna(value):
            return ""
        return str(value).strip()

    for _, row in df.iterrows():
        title = get_title(row)

        job_context_parts = [
            f"Job Title: {safe(row.get('title'))}",
            f"Position: {safe(row.get('position'))}",
            f"Industry: {safe(row.get('job_industry'))}",
            f"Job Type: {safe(row.get('job_type'))}",
            f"Location: {safe(row.get('location'))}",
            f"Job Description: {safe(row.get('job_content'))}",
            f"Required Experience: {safe(row.get('required_experience'))}",
            f"Desired Experience: {safe(row.get('desired_experience'))}",
            f"Target Candidate: {safe(row.get('target_candidate'))}",
            f"Education: {safe(row.get('education'))}",
            f"Eligibility Details: {safe(row.get('eligibility_details'))}",
        ]

        job_context = "\n".join(
            part for part in job_context_parts if part.split(": ", 1)[1]
        )
        seniority = detect_seniority(job_context)
 
        jobs.append({
            "job_id": safe(row.get("job_url")),
            "title": title,
            "job_context": job_context,
            "seniority": seniority,
            "company_name": safe(row.get("company_name")),
            "passrate_for_doc_screening": safe(row.get("passrate_for_doc_screening")),
            "documents_to_job_offer_ratio": safe(row.get("documents_to_job_offer_ratio")),
            "fee": safe(row.get("fee")),
        })

    return jobs
def calculate_score(criteria: dict, seniority: str) -> int:
    weights = {
        "â—‹": 1.0,
        "â–³": 0.6,
        "Ã—": 0.0,
    }

    raw = (
        weights.get(criteria.get("must_have_requirements"), 0) * 0.4 +
        weights.get(criteria.get("preferred_requirements"), 0) * 0.3 +
        weights.get(criteria.get("role_alignment"), 0) * 0.3
    )

    score = int(raw * 100)

    # ğŸ¯ Seniority-based soft floors
    if seniority == "ENTRY":
        score = max(score, 35)
    elif seniority == "MID":
        score = max(score, 20)
    elif seniority == "SENIOR":
        score = max(score, 10)

    return min(score, 100)
    


def ai_match_job(candidate_files, job, model_name, candidate_seniority):

    


    

    
    prompt = f"""
Return ONLY valid JSON.
No markdown.
No explanations.
No text outside JSON.

All string values MUST be single-line.
Do NOT include newline characters inside strings.

ã‚ãªãŸã¯ã€æ›¸é¡é¸è€ƒã‚’æ‹…å½“ã™ã‚‹æ¡ç”¨å®Ÿå‹™è€…ã§ã™ã€‚
ä»¥ä¸‹ã®å±¥æ­´æ›¸ï¼ˆCVï¼‰ã¨è·å‹™å†…å®¹ã‚’æ¯”è¼ƒã—ã€
CVã«æ˜ç¤ºçš„ã«è¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹å†…å®¹ã®ã¿ã‚’æ ¹æ‹ ã¨ã—ã¦è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚

ã€æ±‚äººãƒ¬ãƒ™ãƒ«ã€‘
ã“ã®æ±‚äººã¯ã€Œ{job['seniority']} ãƒ¬ãƒ™ãƒ«ã€ã«åˆ†é¡ã•ã‚Œã¾ã™ã€‚

ã€å€™è£œè€…ãƒ¬ãƒ™ãƒ«ã€‘
ã“ã®å€™è£œè€…ã¯ã€Œ{candidate_seniority} ãƒ¬ãƒ™ãƒ«ã€ã¨æ¨å®šã•ã‚Œã¾ã™ã€‚

ã€ãƒ¬ãƒ™ãƒ«å·®ã«é–¢ã™ã‚‹é‡è¦ãƒ«ãƒ¼ãƒ«ï¼ˆå¿…ãšéµå®ˆï¼‰ã€‘
- å€™è£œè€…ãƒ¬ãƒ™ãƒ«ãŒæ±‚äººãƒ¬ãƒ™ãƒ«ã‚’ä¸Šå›ã‚‹å ´åˆï¼š
  çµŒé¨“ä¸è¶³ã¨ã—ã¦è©•ä¾¡ã—ã¦ã¯ã„ã‘ã¾ã›ã‚“ã€‚
  æ¥­ç•Œã®é•ã„ã€å½¹å‰²æœŸå¾…ã®é•ã„ã€ãƒã‚¸ã‚·ãƒ§ãƒ³ã®ãƒŸã‚¹ãƒãƒƒãƒã¨ã—ã¦èª¬æ˜ã—ã¦ãã ã•ã„ã€‚
- å€™è£œè€…ãƒ¬ãƒ™ãƒ«ãŒæ±‚äººãƒ¬ãƒ™ãƒ«ã¨åŒç­‰ã¾ãŸã¯ä¸‹å›ã‚‹å ´åˆï¼š
  æ±‚äººè¦ä»¶ã«å¯¾ã™ã‚‹çµŒé¨“ã®æœ‰ç„¡ã‚’é€šå¸¸ã©ãŠã‚Šè©•ä¾¡ã—ã¦ãã ã•ã„ã€‚

ã€ãƒ¬ãƒ™ãƒ«åˆ¥è©•ä¾¡æ–¹é‡ã€‘
- ENTRY æ±‚äººã®å ´åˆï¼š
  å®Ÿå‹™çµŒé¨“ã®æ¬ å¦‚ã¯ãƒã‚¤ãƒŠã‚¹è©•ä¾¡ã«ã—ã¦ã¯ã„ã‘ã¾ã›ã‚“ã€‚
  å­¦ç¿’ãƒ»è‚²æˆã«ã‚ˆã£ã¦è£œå®Œå¯èƒ½ãªè¦ç´ ã¯ã€Œâ–³ã€ã¨ã—ã¦å‰å‘ãã«è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚
- MID / SENIOR æ±‚äººã®å ´åˆï¼š
  è·å‹™ã«ç›´æ¥é–¢é€£ã™ã‚‹å®Ÿå‹™çµŒé¨“ã®æœ‰ç„¡ã‚’ã‚ˆã‚Šé‡è¦–ã—ã¦ãã ã•ã„ã€‚

ã€è©•ä¾¡ã®åŸºæœ¬æ–¹é‡ã€‘
- è©•ä¾¡ã¯ã€CVã«æ˜ç¤ºçš„ã«è¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹äº‹å®Ÿã®ã¿ã‚’æ ¹æ‹ ã¨ã—ã¦ãã ã•ã„ã€‚
- æ¨æ¸¬ã€è£œå®Œã€éåº¦ãªè§£é‡ˆã¯ç¦æ­¢ã§ã™ã€‚
- æœªè¨˜è¼‰ã®å†…å®¹ã«ã¤ã„ã¦ã€æ–­å®šçš„ãªå¦å®šã‚’è¡Œã£ã¦ã¯ã„ã‘ã¾ã›ã‚“ã€‚

ã€è©•ä¾¡ãƒ«ãƒ¼ãƒ«ã€‘
- è·å‹™ã«ç›´æ¥é–¢é€£ã™ã‚‹æ˜ç¢ºãªçµŒé¨“ãŒç¢ºèªã§ãã‚‹å ´åˆã¯ã€Œâ—‹ã€ã¨ã—ã¦ãã ã•ã„ã€‚
- é–“æ¥çš„ãƒ»æ±ç”¨çš„ãƒ»é™å®šçš„ãªé–¢é€£çµŒé¨“ãŒç¢ºèªã§ãã‚‹å ´åˆã¯ã€Œâ–³ã€ã¨ã—ã¦ãã ã•ã„ã€‚
- CVä¸Šã«é–¢é€£ã™ã‚‹æ ¹æ‹ ãŒä¸€åˆ‡ç¢ºèªã§ããªã„å ´åˆã®ã¿ã€ŒÃ—ã€ã¨ã—ã¦ãã ã•ã„ã€‚

ã€é‡è¦ãªè£œè¶³ãƒ«ãƒ¼ãƒ«ï¼ˆå¿…ãšéµå®ˆï¼‰ã€‘
- ENTRY æ±‚äººã«ãŠã„ã¦ã¯ã€
  å¿…é ˆè¦ä»¶ã«ãŠã‘ã‚‹ç›´æ¥çµŒé¨“ã®æ¬ å¦‚ã‚’ãƒã‚¤ãƒŠã‚¹è©•ä¾¡ã¨ã—ã¦æ‰±ã£ã¦ã¯ã„ã‘ã¾ã›ã‚“ã€‚
- æ˜ç¢ºãªä¸ä¸€è‡´ãŒç¢ºèªã§ããªã„é™ã‚Šã€
  è·å‹™å†…å®¹ã¨ã®é©åˆæ€§ã‚’ã€Œä½ã„ï¼ˆÃ—ï¼‰ã€ã¨æ–­å®šã—ã¦ã¯ã„ã‘ã¾ã›ã‚“ã€‚
- çµŒé¨“ãŒååˆ†ã«ç¢ºèªã§ãã‚‹å ´åˆã€
  ã€Œåˆ¤æ–­ææ–™ãŒé™ã‚‰ã‚Œã¦ã„ã‚‹ã€ã€Œè‚²æˆå‰æã€ãªã©ã®è¡¨ç¾ã‚’ä½¿ç”¨ã—ã¦ã¯ã„ã‘ã¾ã›ã‚“ã€‚

ã€è©•ä¾¡è¨˜å·ã®å®šç¾©ã€‘
â—‹ï¼šç›´æ¥çš„ã‹ã¤è·å‹™é–¢é€£æ€§ã®é«˜ã„çµŒé¨“ãŒç¢ºèªã§ãã‚‹  
â–³ï¼šé–“æ¥çš„ãƒ»æ±ç”¨çš„ãƒ»é™å®šçš„ãªé–¢é€£çµŒé¨“ã€ã¾ãŸã¯è‚²æˆå‰æã§è©•ä¾¡å¯èƒ½  
Ã—ï¼šé–¢é€£ã™ã‚‹çµŒé¨“ã‚„æ ¹æ‹ ãŒä¸€åˆ‡ç¢ºèªã§ããªã„  

ã€å‡ºåŠ›JSONå½¢å¼ï¼ˆå³å®ˆï¼‰ã€‘
{{
  "score": 0,
  "criteria": {{
    "must_have_requirements": "â—‹|â–³|Ã—",
    "preferred_requirements": "â—‹|â–³|Ã—",
    "role_alignment": "â—‹|â–³|Ã—"
  }}
}}

ã€ã‚¹ã‚³ã‚¢ç®—å‡ºãƒ«ãƒ¼ãƒ«ã€‘
- score ã¯ 0 ã‹ã‚‰ 100 ã®æ•´æ•°ã§è¿”ã—ã¦ãã ã•ã„ã€‚
- criteria ã®è©•ä¾¡çµæœã‚’ç·åˆã—ã¦ score ã‚’ç®—å‡ºã—ã¦ãã ã•ã„ã€‚
- ENTRY æ±‚äººã«ãŠã„ã¦ã¯ã€
  ã€Œâ–³ã€ãŒå¤šã„å ´åˆã§ã‚‚ score ã‚’æ¥µç«¯ã«ä½ãè¨­å®šã—ã¦ã¯ã„ã‘ã¾ã›ã‚“ã€‚
- æ˜ç¢ºãªä¸ä¸€è‡´ï¼ˆÃ—ï¼‰ãŒè¤‡æ•°ç¢ºèªã•ã‚Œã‚‹å ´åˆã®ã¿ã€ä½ã‚¹ã‚³ã‚¢ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚

ã€è·å‹™å†…å®¹ã€‘
{job["job_context"][:1500]}
"""




    try:
        model = genai.GenerativeModel(model_name)

        content_parts = [prompt, *candidate_files]
        
        response = model.generate_content(
            content_parts,
            generation_config={
                "temperature": 0.3,
                "max_output_tokens": 900,
            }
        )

        
        
        # Log candidate count and content parts
        if not response.candidates:
            raise ValueError("Gemini returned no candidates")
        
        content_parts = response.candidates[0].content.parts
        
        st.caption(
            f"ğŸ§  Gemini response parts: {len(content_parts)} "
            f"(includes prompt + {len(candidate_files)} document(s))"
        )
        
        raw = response.text
        parsed = extract_json(raw)
        
        criteria = parsed.get("criteria", {})

        parsed["score"] = calculate_score(
            criteria=criteria,
            seniority=job["seniority"]
        )


        # ğŸ” Heuristic warning: likely ingestion / readability issue
        # Case 1: Document likely unreadable
        if st.session_state.get("total_cv_bytes", 0) < 2000:

            st.warning(
                "âš ï¸ The uploaded document may contain little readable text "
                "(e.g. scanned or image-based PDF)."
            )
        
        # Case 2: Valid evaluation, but no match
        elif (
            parsed.get("score", 0) == 0 and
            all(v == "Ã—" for v in parsed.get("criteria", {}).values())
        ):
            st.info(
                "â„¹ï¸ No matching signals were found for this role. "
                "This likely reflects a genuine CVâ€“job mismatch."
            )





        return {
            "ok": True,
            "data": parsed,
            "raw": raw
        }

    except Exception as e:
        return {
            "ok": False,
            "error": str(e),
            "raw": raw if 'raw' in locals() else None,
            "data": {
                "score": 0,
                "criteria": {
                    "must_have_requirements": "Ã—",
                    "preferred_requirements": "Ã—",
                    "role_alignment": "Ã—"
                }
            }
        }



    

# ----------------------------
# UI
# ----------------------------
uploaded_cvs = st.file_uploader(
    "Upload CV files (PDF / DOCX)",
    type=["pdf", "docx"],
    accept_multiple_files=True,
    key="cv_files"
)

jobs_file = st.file_uploader(
    "Upload jobs Excel file",
    type=["xlsx"],
    key="jobs_excel"
)


# ğŸ”¹ ADD THIS BLOCK HERE (exactly here)
if uploaded_cvs:
    st.success("CV files uploaded")

    st.session_state.cvs = uploaded_cvs

    st.info(f"{len(uploaded_cvs)} CVs uploaded")
    
if uploaded_cvs and jobs_file and st.button("Evaluate CVs"):

    jobs_df = pd.read_excel(jobs_file)
    jobs = get_available_jobs(jobs_df)

    folder_results = []
    
    status = st.empty()
    progress = st.progress(0)

    # ğŸ”¹ Aggregate ALL CVs into ONE candidate
    candidate_files = []
    total_bytes = 0

    st.subheader("ğŸ“ Document ingestion log")

    for f in st.session_state.cvs:
        total_bytes += f.size
        part = to_gemini_part(f)
        candidate_files.append(part)
    
        st.code(
            {
                "filename": f.name,
                "detected_mime_type": mimetypes.guess_type(f.name)[0],
                "file_size_kb": round(f.size / 1024, 2),
            },
            language="json"
        )


    st.session_state.total_cv_bytes = total_bytes

    cv_files = [f.name for f in st.session_state.cvs]
    candidate_seniority = detect_candidate_seniority_from_cv(candidate_files)
    st.session_state.candidate_seniority = candidate_seniority

    st.session_state.candidate_files = candidate_files
    


    
    status.info("Evaluating candidate profile (combined documents)")
    
    cv_results = []
    
    for job_idx, job in enumerate(jobs, start=1):
        status.info(f"Evaluating Job {job_idx}/{len(jobs)}")
    
        result = ai_match_job(
            candidate_files,
            job,
            SELECTED_MODEL,
            candidate_seniority
        )


    
        cv_results.append({
            "job": job,
            "score": result["data"]["score"],
            "criteria": result["data"]["criteria"]
        })
    
    cv_results.sort(key=lambda x: x["score"], reverse=True)
    
    st.session_state.results = [{
        "cv_name": "Combined Candidate Profile",
        "cv_type": "MULTI-DOC",
        "cv_files": cv_files,
        "results": cv_results
    }]
    
    status.success("Evaluation completed")
    progress.progress(1.0)

    
    

    
if st.session_state.results:
    st.subheader("CV Evaluation Results")


    for cv_idx, cv_block in enumerate(st.session_state.results):
        if not cv_block["results"]:
            continue

        best_job = cv_block["results"][0]
        st.success(
            f"Best match for {cv_block['cv_name']}: "
            f"**{best_job['job']['title']}** ({best_job['score']}%)"
        )

        st.markdown(f"## ğŸ“„ {cv_block['cv_name']} ({cv_block['cv_type']})")
        st.divider()
               
        candidate_container = st.container()
        
        with candidate_container:
            st.markdown("**Uploaded Documents:**")
            for name in cv_block.get("cv_files", []):
                st.markdown(f"- {name}")
        
            st.caption(
                "â€» ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸå±¥æ­´æ›¸ã¯ã€AIãŒå†…å®¹ã‚’ç›´æ¥ç†è§£ã—è©•ä¾¡ã—ã¦ã„ã¾ã™ã€‚"
                " è¿½åŠ ã®äº‹å‰å‡¦ç†ã¯ä¸è¦ãªè¨­è¨ˆã®ãŸã‚ã€è¿…é€Ÿã«åˆ†æçµæœã‚’æä¾›ã§ãã¾ã™ã€‚"
            )


        
            for job_idx, r in enumerate(cv_block["results"]):
                job = r["job"]
        
                st.markdown(f"### {job['title']}")
                display_score = get_display_score(
                    r["score"],
                    job["seniority"]
                )
                
                st.write(f"**Estimated Offer Probability:** {display_score}%")

        
                cols = st.columns(3)
                cols[0].markdown(f"**ä¼šç¤¾å**<br>{job['company_name']}", unsafe_allow_html=True)
                cols[1].markdown(
                    f"**æ›¸é¡é€šéç‡**<br>{job['passrate_for_doc_screening']}%",
                    unsafe_allow_html=True
                )
                cols[2].markdown(
                    f"**å†…å®šç‡**<br>{job['documents_to_job_offer_ratio']}",
                    unsafe_allow_html=True
                )

        
                explain_key = f"{cv_idx}_{job_idx}"
        
                if explain_key not in st.session_state.explain_open:
                    st.session_state.explain_open[explain_key] = False
        
                if st.button(
                    f"åˆ†æè©³ç´°ï¼ˆã“ã®è©•ä¾¡ã®ç†ç”±ï¼‰ â€“ {job['title']}",
                    key=f"explain_btn_{explain_key}"
                ):
                    st.session_state.explain_open[explain_key] = True

                    if explain_key not in st.session_state.explanations:
                        st.session_state.explanations[explain_key] = generate_full_assessment(
                            st.session_state.candidate_files,
                            job,
                            SELECTED_MODEL,
                            st.session_state.candidate_seniority
                        )



        
                if st.session_state.explain_open.get(explain_key, False):
                    sections = st.session_state.explanations.get(explain_key)
                    if sections:
                        st.markdown("### ğŸ“ è©•ä¾¡ã‚µãƒãƒªãƒ¼")
                        st.write(sections.get("SUMMARY", ""))
        
                        with st.expander("ğŸ“Š è©•ä¾¡è©³ç´°", expanded=True):

                            st.markdown("**å¿…é ˆè¦ä»¶ï¼ˆMust-haveï¼‰**")
                            st.write(sections.get("MUST_HAVE", ""))
                            st.markdown("**æ­“è¿è¦ä»¶ï¼ˆPreferredï¼‰**")
                            st.write(sections.get("PREFERRED", ""))
                            st.markdown("**æ¥­å‹™è¦ªå’Œæ€§ï¼ˆAlignmentï¼‰**")
                            st.write(sections.get("ALIGNMENT", ""))
        
        
        
                    
