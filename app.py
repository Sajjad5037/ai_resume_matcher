import os
import json
import mimetypes
import pandas as pd
import streamlit as st
import google.generativeai as genai

# ----------------------------
# Gemini Setup
# ----------------------------
genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))

# ----------------------------
# App Config
# ----------------------------
st.set_page_config(page_title="AI Resume Matcher", layout="centered")

st.title("AI Resume Matcher")

st.write(
    "ğŸ“Œ For best accuracy, upload CVs in DOCX or text-based PDF format. "
    "Scanned PDFs may reduce matching quality."
)

# ----------------------------
# Helpers
# ----------------------------
def to_gemini_part(uploaded_file, debug=True):
    if debug:
        st.divider()
        st.subheader("ğŸ“„ Attaching CV to Gemini")

    # Basic file info
    if debug:
        st.write("Filename:", uploaded_file.name)
        st.write("Streamlit MIME:", uploaded_file.type)

    # Reset pointer
    try:
        uploaded_file.seek(0)
        if debug:
            st.success("File pointer reset")
    except Exception as e:
        st.error("âŒ Failed to reset file pointer")
        st.code(repr(e))
        raise

    # Resolve MIME
    mime_type, encoding = mimetypes.guess_type(uploaded_file.name)

    if uploaded_file.name.lower().endswith(".pdf"):
        mime_type = "application/pdf"
        if debug:
            st.info("PDF detected â†’ forcing application/pdf")

    if not mime_type:
        mime_type = uploaded_file.type or "application/octet-stream"
        if debug:
            st.warning("MIME guess failed â†’ using fallback")

    if debug:
        st.write("Final MIME:", mime_type)

    # Read bytes
    data = uploaded_file.read()

    if debug:
        st.write("File size (bytes):", len(data))

    if not data:
        st.error("âŒ CV file is EMPTY (0 bytes). Aborting.")
        raise ValueError(f"CV '{uploaded_file.name}' is empty")

    if debug:
        st.success("CV attached successfully")

    return {
        "inline_data": {
            "mime_type": mime_type,
            "data": data,
        }
    }

#because ai output is consistent so we are making sure
def extract_json(text, debug=True): 
    if debug:
        st.divider()
        st.subheader("ğŸ§© Parsing AI JSON Response")

    if debug:
        st.write("Raw response length:", len(text))
        st.write("Raw response preview:")
        st.code(text[:2000])  # prevent UI overload

    start = text.find("{")
    end = text.rfind("}")

    if start == -1 or end == -1 or end <= start:
        st.error("âŒ No valid JSON boundaries found in AI response")
        if debug:
            st.write("First '{' index:", start)
            st.write("Last '}' index:", end)
        raise ValueError("No valid JSON found in AI response")

    json_str = text[start:end + 1]

    if debug:
        st.success("JSON boundaries detected")
        st.write("Extracted JSON preview:")
        st.code(json_str[:2000])

    try:
        return json.loads(json_str)
    except json.JSONDecodeError as e:
        st.error("âŒ JSON parsing failed")
        if debug:
            st.write("JSON decode error:")
            st.code(repr(e))
            st.write("Full extracted JSON:")
            st.code(json_str)
        raise

#here
def detect_seniority(job_context: str) -> str:
    keywords_entry = ["æœªçµŒé¨“OK", "çµŒé¨“ä¸å•", "ç¬¬äºŒæ–°å’"]
    keywords_senior = ["3å¹´ä»¥ä¸Š", "5å¹´ä»¥ä¸Š", "ãƒªãƒ¼ãƒ‰", "ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼"]

    for k in keywords_entry:
        if k in job_context:
            return "ENTRY"

    for k in keywords_senior:
        if k in job_context:
            return "SENIOR"

    return "MID"


def get_available_jobs(df: pd.DataFrame):
    df.columns = df.columns.astype(str).str.strip()
    jobs = []

    def safe(v):
        return "" if pd.isna(v) else str(v).strip()

    for _, row in df.iterrows():
        job_context_parts = [
            f"ã€è·ç¨®åã€‘{safe(row.get('title'))}",
            f"ã€ãƒã‚¸ã‚·ãƒ§ãƒ³ã€‘{safe(row.get('position'))}",
            f"ã€æ¥­ç•Œã€‘{safe(row.get('job_industry'))}",
            f"ã€å‹¤å‹™åœ°ã€‘{safe(row.get('location'))}",
            f"ã€è·å‹™å†…å®¹ã€‘{safe(row.get('job_content'))}",
        
            # ğŸ”‘ Make these unmistakable
            f"ã€å¿…é ˆè¦ä»¶ï¼ˆæº€ãŸã•ãªã„å ´åˆã€åŸå‰‡æ›¸é¡é€šéä¸å¯ï¼‰ã€‘{safe(row.get('required_experience'))}",
            f"ã€æ­“è¿è¦ä»¶ï¼ˆåŠ ç‚¹è¦ç´ ï¼‰ã€‘{safe(row.get('desired_experience'))}",
        ]


        job_context = "\n".join(
            p for p in job_context_parts if p.strip()
        )


        jobs.append({
            "title": safe(row.get("title")) or "Unknown Role",
            "job_context": job_context,
            "seniority": detect_seniority(job_context),
            "company_name": safe(row.get("company_name")),
        })

    return jobs


# ----------------------------
# AI Core
# ----------------------------
def generate_full_assessment(candidate_files, job, model_name, candidate_seniority):
    prompt = f"""
Return ONLY valid JSON.
No markdown.
No text outside JSON.

ã‚ãªãŸã¯ã€äººæç´¹ä»‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨ã—ã¦
æ›¸é¡é¸è€ƒã®å®Ÿå‹™çµŒé¨“ãŒè±Šå¯Œãªã‚­ãƒ£ãƒªã‚¢ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼ã§ã™ã€‚

ä»¥ä¸‹ã®å±¥æ­´æ›¸ï¼ˆCVï¼‰ã‚’èª­ã¿ã€
ã€Œã“ã®å€™è£œè€…ãŒã€ã“ã®æ±‚äººã®æ›¸é¡é¸è€ƒã‚’é€šéã§ãã‚‹ã‹ã€
ã‚’ã€ç¬¬ä¸‰è€…ã«ã‚‚èª¬æ˜ã§ãã‚‹å½¢ã§è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚

ã€è©•ä¾¡ã®å‰æï¼ˆå¿…ãšå³å®ˆï¼‰ã€‘
- æœ¬è©•ä¾¡ã¯ã€Œæ›¸é¡é¸è€ƒæ®µéšã€ã®åˆ¤æ–­ã§ã™
- CVã«æ˜ç¤ºçš„ã«è¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹å†…å®¹ã®ã¿ã‚’æ ¹æ‹ ã«ã—ã¦ãã ã•ã„
- æ¨æ¸¬ãƒ»è£œå®Œãƒ»å¥½æ„çš„è§£é‡ˆã¯ç¦æ­¢ã§ã™
- æ±‚äººç¥¨ã«è¨˜è¼‰ã•ã‚ŒãŸè¦ä»¶ãƒ»æ–‡è¨€ã‚’æœ€é‡è¦è¦–ã—ã¦ãã ã•ã„
- ENTRYæ±‚äººã§ã¯ã€çµŒé¨“ä¸è¶³ã‚’å¦å®šçš„ã«è©•ä¾¡ã—ã¦ã¯ã„ã‘ã¾ã›ã‚“
- è©•ä¾¡ã¯ã€Œæ¡ç”¨å¯å¦ã®æœ€çµ‚åˆ¤æ–­ã€ã§ã¯ã‚ã‚Šã¾ã›ã‚“

ã€æ±‚äººãƒ¬ãƒ™ãƒ«ã€‘
{job["seniority"]}

ã€å€™è£œè€…ãƒ¬ãƒ™ãƒ«ã€‘
{candidate_seniority}

ã€è©•ä¾¡å¯¾è±¡ã®æ±‚äººæƒ…å ±ã€‘
{job["job_context"][:1500]}

ã€è©•ä¾¡ã®è¦³ç‚¹ã€‘
- å¿…é ˆè¦ä»¶ã¨çµŒæ­´ã®é©åˆæ€§ï¼ˆæœ€é‡è¦ï¼‰
- æ­“è¿è¦ä»¶ã¨çµŒæ­´ã®é©åˆæ€§ï¼ˆåŠ ç‚¹è¦ç´ ï¼‰
- è·å‹™å†…å®¹å…¨ä½“ã¨ã®æ•´åˆæ€§
- ä¸Šè¨˜ã‚’è¸ã¾ãˆãŸæ›¸é¡é€šéã®ç¾å®Ÿçš„å¯èƒ½æ€§

ã€å‡ºåŠ›JSONå½¢å¼ï¼ˆå³å®ˆï¼‰ã€‘
{{
  "SUMMARY": "",
  "MUST_HAVE_REASONING": "",
  "PREFERRED_REASONING": "",
  "ROLE_ALIGNMENT_REASONING": "",
  "score": 0
}}
"""

    model = genai.GenerativeModel(model_name)

    contents = [prompt, *candidate_files]

    response = model.generate_content(
        contents,
        generation_config={
            "temperature": 0.3,
            "max_output_tokens": 900,
        }

    )

    return extract_json(response.text)

# ----------------------------
# UI
# ----------------------------
uploaded_cvs = st.file_uploader(
    "Upload CV files (PDF / DOCX)",
    type=["pdf", "docx"],
    accept_multiple_files=True
)

jobs_file = st.file_uploader(
    "Upload jobs Excel file",
    type=["xlsx"]
)

MODEL_NAME = "models/gemini-1.5-pro-001"

if uploaded_cvs and jobs_file and st.button("Evaluate CVs"):
    jobs_df = pd.read_excel(jobs_file)
    jobs = get_available_jobs(jobs_df)

    candidate_files = []
    for f in uploaded_cvs:
        candidate_files.append(to_gemini_part(f))

    candidate_seniority = "ENTRY"  # intentionally fixed (your original logic)

    st.subheader("ğŸ“Š Results")

    results = []
    
    for job in jobs:
        try:
            result = generate_full_assessment(
                candidate_files,
                job,
                MODEL_NAME,
                candidate_seniority
            )
    
            results.append({
                "job": job,
                "result": result
            })
    
        except Exception as e:
            st.error(f"âŒ Evaluation failed for job: {job['title']}")
            st.code(repr(e))
            continue
    results = sorted(
        results,
        key=lambda x: x["result"]["score"],
        reverse=True
    )
    
    for item in results:
        job = item["job"]
        result = item["result"]
    
        st.markdown(f"### {job['title']}")
        st.write(f"**Score:** {result['score']}%")
    
        st.write("**Summary**")
        st.write(result["SUMMARY"])
    
        st.write("**Must Have**")
        st.write(result["MUST_HAVE_REASONING"])
        
        st.write("**Preferred**")
        st.write(result["PREFERRED_REASONING"])
        
        st.write("**Alignment**")
        st.write(result["ROLE_ALIGNMENT_REASONING"])
    
        st.divider()





